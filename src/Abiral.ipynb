{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25f9b0f-d60c-4193-a001-fcf8f01163c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in e:\\anaconda\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in e:\\anaconda\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in e:\\anaconda\\lib\\site-packages (from python-docx) (4.13.0)\n",
      "Requirement already satisfied: PyPDF2 in e:\\anaconda\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx  \n",
    "!pip install PyPDF2  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32966e15-8d51-4d87-bd21-bacde5ac80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one is by OLLAMA\n",
    "import requests\n",
    "from docx import Document\n",
    "import PyPDF2\n",
    "\n",
    "# Ollama API endpoint (adjust if needed)\n",
    "OLLAMA_URL = \"http://localhost:11434/v1/chat/completions\"\n",
    "\n",
    "# Function to send a prompt to Ollama\n",
    "def ask_ollama(prompt):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama2\",  # Use llama2 or the model you're working with\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7  # Adjust temperature for creativity if needed\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.post(OLLAMA_URL, headers=headers, json=data)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text from Word document (.docx)\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from PDF document\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Function to analyze the CV with the job description using Ollama\n",
    "def analyze_cv_with_job_description(cv_file_path, job_description_file_path):\n",
    "    # Extract text from the resume and job description files\n",
    "    if cv_file_path.endswith(\".docx\"):\n",
    "        cv_text = extract_text_from_docx(cv_file_path)\n",
    "    elif cv_file_path.endswith(\".pdf\"):\n",
    "        cv_text = extract_text_from_pdf(cv_file_path)\n",
    "    else:\n",
    "        return \"Unsupported CV file format\"\n",
    "\n",
    "    if job_description_file_path.endswith(\".docx\"):\n",
    "        job_description_text = extract_text_from_docx(job_description_file_path)\n",
    "    elif job_description_file_path.endswith(\".pdf\"):\n",
    "        job_description_text = extract_text_from_pdf(job_description_file_path)\n",
    "    else:\n",
    "        return \"Unsupported Job Description file format\"\n",
    "\n",
    "    # Construct the prompt for Ollama\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following resume with the job description:\n",
    "    Resume: {cv_text}\n",
    "    Job Description: {job_description_text}\n",
    "    Provide a similarity score, and suggest areas to improve in the resume to make it better aligned with the job description.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the analysis from Ollama\n",
    "    result = ask_ollama(prompt)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "cv_file_path = \"resume.docx\"  # Replace with your actual file path\n",
    "job_description_file_path = \"job_description.docx\"  # Replace with your actual file path\n",
    "\n",
    "# Get the analysis\n",
    "result = analyze_cv_with_job_description(cv_file_path, job_description_file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c65852-ee2f-4dc3-b4a7-60c8a0f0240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one is from openai\n",
    "pip install python-docx  # For Word documents\n",
    "pip install PyPDF2  # For PDFs (Alternatively use pdfplumber)\n",
    "pip install openai  # For OpenAI API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316948a5-9866-4711-b518-3df1c0497056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from docx import Document\n",
    "import PyPDF2\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'your-openai-api-key'  # Replace with your OpenAI API key\n",
    "\n",
    "# Function to extract text from Word document (.docx)\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from PDF document\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Function to send a prompt to OpenAI for analysis\n",
    "def ask_openai(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",  # You can use \"gpt-3.5-turbo\" or other available models\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7  # Adjust temperature for creativity if needed\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Function to analyze the CV with the job description using OpenAI\n",
    "def analyze_cv_with_job_description(cv_file_path, job_description_file_path):\n",
    "    # Extract text from the resume and job description files\n",
    "    if cv_file_path.endswith(\".docx\"):\n",
    "        cv_text = extract_text_from_docx(cv_file_path)\n",
    "    elif cv_file_path.endswith(\".pdf\"):\n",
    "        cv_text = extract_text_from_pdf(cv_file_path)\n",
    "    else:\n",
    "        return \"Unsupported CV file format\"\n",
    "\n",
    "    if job_description_file_path.endswith(\".docx\"):\n",
    "        job_description_text = extract_text_from_docx(job_description_file_path)\n",
    "    elif job_description_file_path.endswith(\".pdf\"):\n",
    "        job_description_text = extract_text_from_pdf(job_description_file_path)\n",
    "    else:\n",
    "        return \"Unsupported Job Description file format\"\n",
    "\n",
    "    # Construct the prompt for OpenAI\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following resume with the job description:\n",
    "    Resume: {cv_text}\n",
    "    Job Description: {job_description_text}\n",
    "    Provide a similarity score, and suggest areas to improve in the resume to make it better aligned with the job description.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the analysis from OpenAI\n",
    "    result = ask_openai(prompt)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "cv_file_path = \"resume.docx\"  # Replace with your actual file path\n",
    "job_description_file_path = \"job_description.docx\"  # Replace with your actual file path\n",
    "\n",
    "# Get the analysis\n",
    "result = analyze_cv_with_job_description(cv_file_path, job_description_file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f0c35d-6577-4be2-a9c0-79450b1a885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/Abiral-checkpoint.ipynb\n",
      "\tAbiral.ipynb\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e66c4dd-a7df-47dc-a2be-d553fbf06cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "!git add <Abiral.ipynb>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841978d4-debb-4946-9745-f126d9a50faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
